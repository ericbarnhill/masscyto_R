---
title: "Bayesian Uncertainty Modelling in A Mass Cytometry Experiment"
author: "Eric Barnhill and Shravan Vasishth"
date: "February 19, 2018"
output:
  pdf_document: default
  html_document: default
header-includes: \usepackage{bbm}
---

Some additional code and analyses by Shravan Vasishth (vasishth at uni-potsdam.de).

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#knitr::opts_chunk$set(root.dir = "/home/ericbarnhill/Documents/code/R/2017-12-15-masscyto")
require(EasyABC)
require(gdata)
require(tidyr)
require(rlist)
require(ggplot2)
require(HDInterval)
require(reshape2)
require(rjags)
require(RColorBrewer)
library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
library(brms)
library(lme4)
```

## Introduction

The goal of this experiment was to estimate robustness and uncertainty of effects in a mass cytometry  experiment. In this experiment, the response of contrast agents in six cell types was studied. As the cell types behave biologically differently, a separate statistical model was built for each.

In each model, three experiments were run, in which cell samples were subjected to three differing contrast agents:

- Magnevist
- Dotarem
- Gadevist

and a control condition. Cells were subjected to these agents at three differing concentrations: 0.1, 0.3, and 1, and the control condition was considered a concentration of 0.0. Thus a fully specified model for the experiment would be:

$$
E(Y_{ijk}) = \beta_{0} + u_{0j} + w_{0k} + (\beta_{1} + u_{1j} + w_{1k})conc_{i} + \epsilon_{i}
$$
where $\beta_{0}$ is the global intercept, $u_{0j}$ is a random intercept for experiment, $w_{0k}$ is a random intercept for contrast agent, and similarly, $\beta_{1}$, $u_{1j}$ and $w_{1k}$ are adjustments to the slope of the continuous concentration variable $conc$.

The data were acquired with a mass cytometer which provides several thousand measurements for each category. A summary plot from the mass cytometer for one experiment is below:

![Cytometer Output](cytometer_output.png)
For this experiment we asked the scientific question: Does the cell signal change with contrast agent, for a given concentration?

Interpretation of this data with a rigorous statistical model posed two major challenges:

- Mass cytometry data is rarely handled in its raw form, which contains millions of samples. Rather, the cytometer outputs four summary statistics: 10% quantile, mean, median, and 90% quantile. To model uncertainty, the underlying distribution of each experimental condition had to be estimated.
- Once the distributions for each condition were estimated, iterative model-building was required to estimate impact of contrast agent.

## Data exploration

Data were cleaned and converted to tall format:


```{r}
source('masscyto_clean_gather_dataNEW.R')
mass_cyto <- read.xls(xls="experimental_data.xlsx", 
                      header=FALSE, skip=3, nrows=30)[,-(5:10)]
mass_cyto_tall <- clean_gather_data(mass_cyto)
#str(mass_cyto_tall)
#head(mass_cyto_tall)
#summary(mass_cyto_tall)
```

The research question: Does the cell signal change with contrast agent, for a given concentration?

Eric wrote:

  ``The main experimental question is whether certain of the contrast agents, which are safer, produce signal comparable to other contrast agents which are more dangerous. However, we do also want to investigate whether this statement holds at varying concentrations.'' 

To me (SV), this sounds like we need to know if there is an interaction between ContrastAgent and concentration, but the crucial issue is: is there a specific expectation for how ContrastAgent will affect the dependent variable value?  For now, I will assume that there is a natural ordering in level of danger:

- Magnevist is less dangerous than Dotarem
- Dotarem is less dangerous than Gadevist

These comparisons can be changed to reflect reality (if the above ordering is incorrect).

We will use sliding contrasts to reflect the above ordering:


```{r}
library(MASS)
## reversing the signs by multiplying by -1:
comparisons<- -1*round(ginv(contr.sdif(3)))
rownames(comparisons)<-c("MvsD","DvsG")
comparisons
```

Also, we would have to remove control from that particular analysis, because controls have only one level of the concentrations. But the effect of control can be estimated and used as a baseline (to-do).

Experiment needs to be modeled as a random effect because each experiment is actually a patient. 

## Computing standard deviation of the dependent variable ``value'' in preparation for measurement error modeling

We can just take logs on the mean and the quantile measurements and then get the measurement error on the log scale:

```{r}
x<-rlnorm(1000,meanlog=1.2,sdlog=1)
qnorm(0.05,mean=1.2,sd=1) # 5% quantile
qnorm(0.95,mean=1.2,sd=1) # 95% quantile
mean(log(x)) ## recovers MLE of lognormal
sd(log(x))   ## recovers sd of lognormal
log(quantile(x,prob=c(0.05,0.95))) ## recovers 5th and 95th quantile
```

So, given the upper 95th percentile, we take the distance between this percentile value and the sample mean, and divide that by 1.64 or so to get an approximate standard deviation. We will use this in the measurement error model.

## Modeling effect of concentration

In preparation for the measurement error model, we first  
prepare the data so that there is a column for the uncertainty of each mean value in each row of the data frame:

```{r}
## extract means:
means<-subset(mass_cyto_tall,MeasurementType=="Mean")
## extract lower quantiles:
qlow<-subset(mass_cyto_tall,MeasurementType=="pct_05")
## extract upper quantiles:
qhigh<-subset(mass_cyto_tall,MeasurementType=="pct_95")

## log scale difference between upper percentile and mean:
d<-log(qhigh$value)-log(means$value)

means$SD<-d/1.64

## center concentration:
means$cconc<-scale(as.numeric(as.character(means$Concentration)),scale=FALSE)

#head(means)

## rename cell type as numerical values:
means$typ<-unique(as.numeric(means$CellType))

dat<-list(cconc=as.vector(means$cconc),
     value=log(means$value),
     SD=means$SD,
     typ=as.integer(means$typ),
     N = dim(means)[1],
     J = length(unique(means$typ))
     )

str(dat)
```

The first step is to visualize the effect of concentration by contrast agent and experiment, pooling data from all cell types:

```{r}
library(lattice)
xyplot(log(value)~Concentration|ContrastAgent+Experiment,means)
```

We start by just modeling the effect of concentration on log(value).  Concentration is centered and scaled to have standard deviation 1; this has the (small) advantage that the intercept now has the interpretation that it reflects the predicted log(value) when concentration is the average value. 

Here is the standard hierarchical linear model of effect of concentration on log value. Cell Types and Experiment are treated as random effects. Here I am making the simplifying assumption that Cell Types and Experiment are independent---is this reasonable? 



```{r concentrationlmer}
m1<-lmer(log(value)~cconc+(1+cconc|Experiment)+
          (1+cconc|CellType),
        subset(means,ContrastAgent!="control"))

print(summary(m1))
```

The above frequentist model has some problems. In particular, it cannot estimate the correlations (notice that these are $\pm 1$). I would therefore fit a simpler frequentist model, assuming no correlations between the varying intercepts and slopes:

```{r concentrationlmer2}
m2<-lmer(log(value)~cconc+(1+cconc||Experiment)+
          (1+cconc||CellType),
        subset(means,ContrastAgent!="control"))

print(summary(m2))
```

The full model above (m1) can be fit in Stan quite easily. As priors for the fixed effects we choose Cauchy(0,5), to allow them to have extreme values, and for the others, we choose Normal(0,1), which seems reasonable as the dependent variable is on the log scale and the standard deviations are all going to be less than 1. The correlation parameters have as priors the LKJ(2) prior, which downweights the extreme values $\pm 1$.

```{r concentrationbrms,cache=TRUE}
priors<-c(set_prior("cauchy(0,5)", 
                    class = "b"),
                      set_prior("cauchy(0,5)", class = "b",coef="cconc"),set_prior("normal(0,1)", class = "sd"), set_prior("normal(0,1)", class = "sigma"),
          set_prior("lkj(2)", class = "cor"))

m1brm<-brm(formula = log(value) ~ cconc+(1+cconc|Experiment)+
          (1+cconc|CellType),
            data = subset(means,ContrastAgent!="control"), 
            family = gaussian(),
            prior = priors,
            warmup = 1000, 
            iter = 2000, 
            chains = 4,
            control = list(adapt_delta = 0.99,max_treedepth=15))
print(summary(m1brm))
```

Notice some important differences between the frequentist model (FM) and the Bayesian model (BM): The FM fails to estimate the intercept-slope correlations; the BM is able to estimate the correlations, but also shows very high uncertainty in the posterior distributions of these correlations. The BM also provides 95% credible intervals for each parameter; the FM only does this for the fixed effects parameters (the intercept and the effect of concentration).

Plotting the posteriors:

```{r}
plot(m1brm,N=9)
```



## Modeling effect of contrast agent and its interaction with concentration

Because of the complexity of the model, I will not attempt to fit correlations in the frequentist model:

```{r}
## hand-coded sliding contrasts:
means$MvsD<-ifelse(means$ContrastAgent=="Magnevist",1,
           ifelse(means$ContrastAgent=="Dotarem",-1,0))
means$DvsG<-ifelse(means$ContrastAgent=="Dotarem",1,
           ifelse(means$ContrastAgent=="Gadovist",-1,0))

m3<-lmer(log(value)~ cconc +MvsD+DvsG+cconc:MvsD + cconc:DvsG+(1+cconc +MvsD+DvsG+cconc:MvsD + cconc:DvsG||Experiment)+(1+cconc +MvsD+DvsG+cconc:MvsD + cconc:DvsG||CellType),
                 subset(means,ContrastAgent!="control"))
print(summary(m3))
}
```

Stan version:

```{r cache=TRUE}
m3brm<-brm(formula = log(value)~ cconc +MvsD+DvsG+cconc:MvsD + cconc:DvsG+
             (1+cconc +MvsD+DvsG+cconc:MvsD + cconc:DvsG|Experiment)+
             (1+cconc +MvsD+DvsG+cconc:MvsD + cconc:DvsG|CellType),
            data = subset(means,ContrastAgent!="control"), 
            family = gaussian(),
            prior = priors,
            warmup = 1000, 
            iter = 2000, 
            chains = 4,
            control = list(adapt_delta = 0.99,max_treedepth=15))
print(summary(m3brm))
```

## Measurement error on log(value)

to-do