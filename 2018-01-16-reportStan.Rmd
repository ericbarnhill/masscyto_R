---
title: "Bayesian Uncertainty Modelling in A Mass Cytometry Experiment"
author: "Eric Barnhill and Shravan Vasishth"
date: "February 19, 2018"
output:
  pdf_document: default
  html_document: default
header-includes: \usepackage{bbm}
---

Some additional code and analyses by Shravan Vasishth (vasishth at uni-potsdam.de).

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#knitr::opts_chunk$set(root.dir = "/home/ericbarnhill/Documents/code/R/2017-12-15-masscyto")
require(EasyABC)
require(gdata)
require(tidyr)
require(rlist)
require(ggplot2)
require(HDInterval)
require(reshape2)
require(rjags)
require(RColorBrewer)
library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
library(brms)
library(lme4)
```

## Introduction

The goal of this experiment was to estimate robustness and uncertainty of effects in a mass cytometry  experiment. In this experiment, the response of contrast agents in six cell types was studied. As the cell types behave biologically differently, a separate statistical model was built for each.

In each model, three experiments were run, in which cell samples were subjected to three differing contrast agents:

- Magnevist
- Dotarem
- Gadevist

and a control condition. Cells were subjected to these agents at three differing concentrations: 0.1, 0.3, and 1, and the control condition was considered a concentration of 0.0. Thus a fully specified model for the experiment would be:

$$
E(Y_{ijk}) = \beta_{0} + u_{0j} + w_{0k} + (\beta_{1} + u_{1j} + w_{1k})conc_{i} + \epsilon_{i}
$$
where $\beta_{0}$ is the global intercept, $u_{0j}$ is a random intercept for experiment, $w_{0k}$ is a random intercept for contrast agent, and similarly, $\beta_{1}$, $u_{1j}$ and $w_{1k}$ are adjustments to the slope of the continuous concentration variable $conc$.

The data were acquired with a mass cytometer which provides several thousand measurements for each category. A summary plot from the mass cytometer for one experiment is below:

![Cytometer Output](cytometer_output.png)
For this experiment we asked the scientific question: Does the cell signal change with contrast agent, for a given concentration?

Interpretation of this data with a rigorous statistical model posed two major challenges:

- Mass cytometry data is rarely handled in its raw form, which contains millions of samples. Rather, the cytometer outputs four summary statistics: 10% quantile, mean, median, and 90% quantile. To model uncertainty, the underlying distribution of each experimental condition had to be estimated.
- Once the distributions for each condition were estimated, iterative model-building was required to estimate impact of contrast agent.

## Data exploration

Data were cleaned and converted to tall format:


```{r}
source('masscyto_clean_gather_dataNEW.R')
mass_cyto <- read.xls(xls="experimental_data.xlsx", 
                      header=FALSE, skip=3, nrows=30)[,-(5:10)]
mass_cyto_tall <- clean_gather_data(mass_cyto)
#str(mass_cyto_tall)
#head(mass_cyto_tall)
#summary(mass_cyto_tall)
```

The research question: Does the cell signal change with contrast agent, for a given concentration?

Eric wrote:

  ``The main experimental question is whether certain of the contrast agents, which are safer, produce signal comparable to other contrast agents which are more dangerous. However, we do also want to investigate whether this statement holds at varying concentrations.'' 

To me (SV), this sounds like we need to know if there is an interaction between ContrastAgent and concentration, but the crucial issue is: is there a specific expectation for how ContrastAgent will affect the dependent variable value?  For now, I will assume that there is a natural ordering in level of danger:

- Magnevist is less dangerous than Dotarem
- Dotarem is less dangerous than Gadevist

These comparisons can be changed to reflect reality (if the above ordering is incorrect).

We will use sliding contrasts to reflect the above ordering:


```{r}
library(MASS)
## reversing the signs by multiplying by -1:
comparisons<- -1*round(ginv(contr.sdif(3)))
rownames(comparisons)<-c("MvsD","DvsG")
comparisons
```

Also, we would have to remove control from that particular analysis, because controls have only one level of the concentrations. But the effect of control can be estimated and used as a baseline (to-do).

Experiment needs to be modeled as a random effect because each experiment is actually a patient. 

## Computing standard deviation of the dependent variable ``value'' in preparation for measurement error modeling

We can just take logs on the mean and the quantile measurements and then get the measurement error on the log scale:

```{r}
x<-rlnorm(1000,meanlog=1.2,sdlog=1)
qnorm(0.05,mean=1.2,sd=1) # 5% quantile
qnorm(0.95,mean=1.2,sd=1) # 95% quantile
mean(log(x)) ## recovers MLE of lognormal
sd(log(x))   ## recovers sd of lognormal
log(quantile(x,prob=c(0.05,0.95))) ## recovers 5th and 95th quantile
```

So, given the upper 95th percentile, we take the distance between this percentile value and the sample mean, and divide that by 1.64 or so to get an approximate standard deviation. We will use this in the measurement error model.

## Modeling effect of concentration

In preparation for the measurement error model, we first  
prepare the data so that there is a column for the uncertainty of each mean value in each row of the data frame:

```{r}
## extract means:
means<-subset(mass_cyto_tall,MeasurementType=="Mean")
## extract lower quantiles:
qlow<-subset(mass_cyto_tall,MeasurementType=="pct_05")
## extract upper quantiles:
qhigh<-subset(mass_cyto_tall,MeasurementType=="pct_95")

## log scale difference between upper percentile and mean:
d<-log(qhigh$value)-log(means$value)

means$SD<-d/1.64

## center concentration:
means$cconc<-scale(as.numeric(as.character(means$Concentration)),scale=FALSE)

#head(means)

## rename cell type as numerical values:
means$typ<-as.integer(as.factor(means$CellType))

## needed later for measurement error model written in Stan:
dat<-list(cconc=as.vector(means$cconc),
     logvalue=log(means$value),
     SD=means$SD,
     typ=means$typ,
     N = dim(means)[1],
     J = length(unique(means$typ))
     )

str(dat)
```

The first step is to visualize the effect of concentration by contrast agent and experiment, pooling data from all cell types:

```{r}
library(lattice)
xyplot(log(value)~Concentration|ContrastAgent+Experiment,means)
```

We start by just modeling the effect of concentration on log(value).  Concentration is centered and scaled to have standard deviation 1; this has the (small) advantage that the intercept now has the interpretation that it reflects the predicted log(value) when concentration is the average value. 

Here is the standard hierarchical linear model of effect of concentration on log value. Cell Types and Experiment are treated as random effects. Here I am making the simplifying assumption that Cell Types and Experiment are independent---is this reasonable? 



```{r concentrationlmer}
m1<-lmer(log(value)~cconc+(1+cconc|Experiment)+
          (1+cconc|CellType),
        subset(means,ContrastAgent!="control"))

print(summary(m1))
```

The above frequentist model has some problems. In particular, it cannot estimate the correlations (notice that these are $\pm 1$). I would therefore fit a simpler frequentist model, assuming no correlations between the varying intercepts and slopes:

```{r concentrationlmer2}
m2<-lmer(log(value)~cconc+(1+cconc||Experiment)+
          (1+cconc||CellType),
        subset(means,ContrastAgent!="control"))

print(summary(m2))
```

The full model above (m1) can be fit in Stan quite easily. As priors for the fixed effects we choose Cauchy(0,5), to allow them to have extreme values, and for the others, we choose Normal(0,1), which seems reasonable as the dependent variable is on the log scale and the standard deviations are all going to be less than 1. The correlation parameters have as priors the LKJ(2) prior, which downweights the extreme values $\pm 1$.

```{r concentrationbrms,cache=TRUE}
priors<-c(set_prior("cauchy(0,5)", 
                    class = "b"),
                      set_prior("cauchy(0,5)", class = "b",coef="cconc"),set_prior("normal(0,1)", class = "sd"), set_prior("normal(0,1)", class = "sigma"),
          set_prior("lkj(2)", class = "cor"))

m1brm<-brm(formula = log(value) ~ cconc+(1+cconc|Experiment)+
          (1+cconc|CellType),
            data = subset(means,ContrastAgent!="control"), 
            family = gaussian(),
            prior = priors,
            warmup = 1000, 
            iter = 2000, 
            chains = 4,
            control = list(adapt_delta = 0.99,max_treedepth=15))
print(summary(m1brm))
```

Notice some important differences between the frequentist model (FM) and the Bayesian model (BM): The FM fails to estimate the intercept-slope correlations; the BM is able to estimate the correlations, but also shows very high uncertainty in the posterior distributions of these correlations. The BM also provides 95% credible intervals for each parameter; the FM only does this for the fixed effects parameters (the intercept and the effect of concentration).

Plotting the posteriors:

```{r fig.height=12}
plot(m1brm,N=9)
```

## Modeling the effect of contrast agent and their interactions with concentration

Because of the complexity of the model, in the frequentist model I will not attempt to fit correlations in the frequentist model:

```{r}
## hand-coded sliding contrasts:
means$MvsD<-ifelse(means$ContrastAgent=="Magnevist",1,
           ifelse(means$ContrastAgent=="Dotarem",-1,0))
means$DvsG<-ifelse(means$ContrastAgent=="Dotarem",1,
           ifelse(means$ContrastAgent=="Gadovist",-1,0))

m3<-lmer(log(value)~ cconc +MvsD+DvsG+cconc:MvsD + cconc:DvsG+(1+cconc +MvsD+DvsG+cconc:MvsD + cconc:DvsG||Experiment)+(1+cconc +MvsD+DvsG+cconc:MvsD + cconc:DvsG||CellType),
                 subset(means,ContrastAgent!="control"))
print(summary(m3))
```

The vertical bars in the random effects are expressing the assumption that the correlation between intercepts and slopes in random effects is assumed to be 0.

Stan version implemented in brms. Here we are fitting the maximal model, because we can (due to the regularization that the priors provide on the parameters).

```{r cache=TRUE}
m3brm<-brm(formula = log(value)~ cconc +MvsD+DvsG+cconc:MvsD + cconc:DvsG+
             (1+cconc +MvsD+DvsG+cconc:MvsD + cconc:DvsG|Experiment)+
             (1+cconc +MvsD+DvsG+cconc:MvsD + cconc:DvsG|CellType),
            data = subset(means,ContrastAgent!="control"), 
            family = gaussian(),
            prior = priors,
            warmup = 1000, 
            iter = 2000, 
            chains = 4,
            control = list(adapt_delta = 0.99,max_treedepth=15))
print(summary(m3brm))
```

## Measurement error on log(value): the effect of concentration

I switch to Stan instead of brms because this way I am very sure of the underlying generative process. With brms I am not sure if it is working correctly (I am working with the developer to fix the bug in brms).

We start with a varying intercepts-only model.

```{r concentrationME,cache=TRUE}
Mconc <- stan(file = "StanModels/MeasErrVarInt.stan", 
                    data = dat,
                    iter = 4000, 
                    chains = 4,
              control = list(adapt_delta = 0.99,
max_treedepth = 15))
print(Mconc,pars=c("beta","sigma_e","sigma_u"))
```

Some minor sampling problems are apparent in the trace plots, but these can be fixed quickly with reparameterization (in any case, they become irrelevant in the maximal model below). 

```{r}
traceplot(Mconc,pars=c("beta","sigma_e","sigma_u"))
```

Next, we fit a maximal model with varying intercepts for cell type:

```{r concentrationMEMaximal,cache=TRUE}
MconcMaximal <- stan(file = "StanModels/MEVarIntMaximal.stan", 
                    data = dat,
                    iter = 2000, 
                    chains = 4,
              control = list(adapt_delta = 0.99,
max_treedepth = 15))
print(MconcMaximal,pars=c("beta","sigma_e","sigma_u","Conc","diff_by_celltype"))
```

We can plot the results as shown below:

```{r fig.height=12}
stan_hist(MconcMaximal,pars=c("beta","sigma_e","sigma_u","rho_u[1,2]","Conc","diff_by_celltype"))
```

The effects by cell type are also shown, and the mapping from cell type by number id (1-6) to actual cell type names can be inferred from:

```{r}
xtabs(~typ+CellType,means)
```

Also, notice that the correlation parameter has a *lot* of uncertainty; basically any value between -1 and +1 is possible, and the extreme values are downweighted due to the LKJ prior on the correlation.

Next, we will fit the full measurement error model, with main effects and interactions of concentration and contrast agent.

```{r}
means$cconcMvsD <- means$cconc*means$MvsD
means$cconcDvsG <- means$cconc*means$DvsG

dat2<-list(cconc=as.vector(means$cconc),
     logvalue=log(means$value),
     MvsD=means$MvsD,
     DvsG=means$DvsG,
     cconcMvsD = as.vector(means$cconcMvsD),
     cconcDvsG = as.vector(means$cconcDvsG),
     SD=means$SD,
     typ=means$typ,
     N = dim(means)[1],
     J = length(unique(means$typ))
     )
```

```{r concentrationMEMaximal2,cache=TRUE}
MconcMaximal2 <- stan(file = "StanModels/MEVarIntMaximal2.stan", 
                    data = dat2,
                    iter = 2000, 
                    chains = 4,
              control = list(adapt_delta = 0.99,
max_treedepth = 15))
print(MconcMaximal2,pars=c("beta","sigma_e","sigma_u","Conc","rho_u"))
```

The traceplot shows that the residual error needs to be reparameterized (to-do), but all other parameters are converging nicely.

```{r}
traceplot(MconcMaximal2,pars=c("beta","sigma_e","sigma_u","rho_u[1,2]","rho_u[1,3]","rho_u[1,4]","rho_u[1,5]","rho_u[1,6]","rho_u[2,3]","rho_u[2,4]","rho_u[2,5]","rho_u[2,6]","rho_u[3,4]","rho_u[3,5]","rho_u[3,6]","rho_u[4,5]","rho_u[4,6]","rho_u[5,6]","Conc"))
```

```{r fig.height=12}
stan_hist(MconcMaximal2,pars=c("beta","sigma_e","sigma_u","rho_u[1,2]","rho_u[1,3]","rho_u[1,4]","rho_u[1,5]","rho_u[1,6]","rho_u[2,3]","rho_u[2,4]","rho_u[2,5]","rho_u[2,6]","rho_u[3,4]","rho_u[3,5]","rho_u[3,6]","rho_u[4,5]","rho_u[4,6]","rho_u[5,6]","Conc"))
```
